# Web Scraping & Data Storage with Docker, Python & MySQL

## ğŸ“Œ Project Overview
This project automates web scraping using Python and stores the scraped data into a MySQL database, all within a Dockerized environment. By containerizing the application, we ensure portability, scalability, and ease of deployment.

## ğŸš€ Technologies Used
- **Python** (requests, BeautifulSoup, mysql.connector, time)
- **MySQL** (Dockerized database for data storage)
- **Docker** (Containerized environment for easy deployment)

## ğŸ“‚ Project Structure
```
â”œâ”€â”€ app.py                 # Python script for web scraping & storing data
â”œâ”€â”€ Dockerfile             # Dockerfile to build the image
â”œâ”€â”€ requirements.txt       # Dependencies required for the project
â””â”€â”€ README.md              # Project documentation
```

## ğŸ”§ Setup & Installation
### 1ï¸âƒ£ Pull & Run MySQL Docker Image
```sh
docker pull mysql:latest
docker run --name mysql-container -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=scraping_db -p 3306:3306 -d mysql:latest
```

### 2ï¸âƒ£ Clone This Repository
```sh
git clone <your-github-repo-link>
cd <your-project-folder>
```

### 3ï¸âƒ£ Configure `app.py`
Update **database connection details** in `app.py`:
```python
mysql_host = "<MYSQL_CONTAINER_IP>"
mysql_user = "root"
mysql_password = "root"
database = "scraping_db"
```

### 4ï¸âƒ£ Build & Run the Docker Image
```sh
docker build -t web-scraper .
docker run --name scraper-container --link mysql-container -d web-scraper
```

## ğŸ“œ How It Works
1. **Web Scraping:** `app.py` fetches data from a URL using `requests` & `BeautifulSoup`.
2. **Database Storage:** Scraped data is inserted into the MySQL database.
3. **Dockerized Execution:** Running the Docker image automates the entire process.

## ğŸ“Œ Future Enhancements
- Add **logging & error handling**
- Implement **scheduled scraping** with `cron` or `Celery`
- Create a **REST API** to fetch stored data

## ğŸ›  Contributing
Feel free to fork this repo, improve the project, and create a pull request! ğŸš€

## ğŸ“© Connect with Me
For any queries or discussions, connect with me on [LinkedIn](https://www.linkedin.com/in/dipakrasal2009/)!

---

### ğŸ“Œ **Project Repository:** [GitHub Link](https://github.com/dipakrasal2009/Web_Scraper_Python)


